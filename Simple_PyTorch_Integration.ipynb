{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIryQ6UKadRB1uNDa2wy3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iamjuhwan/Deep-Learing/blob/main/Simple_PyTorch_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight & Bias ‚ûï PyTorch"
      ],
      "metadata": {
        "id": "GN1HlJZ3q8v_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HfLHDoU690HD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "460a0956-e540-4d8f-bd9a-3b6c57f56340"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250324_144635-l0pvtg7d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model/runs/l0pvtg7d' target=\"_blank\">legendary-wood-2</a></strong> to <a href='https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model' target=\"_blank\">https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model/runs/l0pvtg7d' target=\"_blank\">https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model/runs/l0pvtg7d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jesujuwonsamuelegbewale-fola/new-sota-model/runs/l0pvtg7d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7808cd072d50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# start a new experiment\n",
        "wandb.init(project=\"new-sota-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import W&B and Login"
      ],
      "metadata": {
        "id": "EaI0yaDerXh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "gCVj_Kn9k5Tu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)"
      ],
      "metadata": {
        "id": "ouyJsGaDlejP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# remove slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]"
      ],
      "metadata": {
        "id": "tnXkZ6QJlh-K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üë©‚Äçüî¨ Define the Experiment and Pipeline"
      ],
      "metadata": {
        "id": "GMdp8eM_rLhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2:Track metadata and hyperparameters with wandb.init"
      ],
      "metadata": {
        "id": "OECZxtKarOPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=5,\n",
        "    classes=10,\n",
        "    kernels=[16, 32],\n",
        "    batch_size=128,\n",
        "    learning_rate=0.005,\n",
        "    dataset=\"MNIST\",\n",
        "    architecture=\"CNN\")"
      ],
      "metadata": {
        "id": "ZZtWDt_lXsfE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=\"pytorch-demo\", config=hyperparameters):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "      print(model)\n",
        "\n",
        "      # and use them to train the model\n",
        "      train(model, train_loader, criterion, optimizer, config)\n",
        "\n",
        "      # and test its final performance\n",
        "      test(model, test_loader)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BDZqE9UqkYLO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    train, test = get_data(train=True), get_data(train=False)\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = ConvNet(config.kernels, config.classes).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "LIfvOk_blqif"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3:  Define the Data Loading and Model"
      ],
      "metadata": {
        "id": "fP_LSRbEsuTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(slice=5, train=True):\n",
        "    full_dataset = torchvision.datasets.MNIST(root=\".\",\n",
        "                                              train=train,\n",
        "                                              transform=transforms.ToTensor(),\n",
        "                                              download=True)\n",
        "    #  equiv to slicing with [::slice]\n",
        "    sub_dataset = torch.utils.data.Subset(\n",
        "      full_dataset, indices=range(0, len(full_dataset), slice))\n",
        "\n",
        "    return sub_dataset\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "aYMH0v2CmfAT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conventional and convolutional neural network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, kernels, classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "          out = self.layer1(x)\n",
        "          out = self.layer2(out)\n",
        "          out = out.reshape(out.size(0), -1)\n",
        "          out = self.fc(out)\n",
        "          return\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "TqrqVq4QmiLG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. Track gradients with wandb.watch and everything else with wandb.log"
      ],
      "metadata": {
        "id": "9kJRzs5ss43b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, criterion, optimizer, config):\n",
        "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    total_batches = len(loader) * config.epochs\n",
        "    example_ct = 0  # number of examples seen\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        for _, (images, labels) in enumerate(loader):\n",
        "\n",
        "            loss = train_batch(images, labels, model, optimizer, criterion)\n",
        "            example_ct +=  len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # Report metrics every 25th batch\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)"
      ],
      "metadata": {
        "id": "6MSNp-cxmmXi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass ‚û°\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass ‚¨Ö\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Az4CcjxknFrB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "YfnSBbvRnIU2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5:  Define Testing Logic"
      ],
      "metadata": {
        "id": "wr0GsMRItBaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Accuracy of the model on the {total} \" +\n",
        "              f\"test images: {correct / total:%}\")\n",
        "\n",
        "        wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "    # Save the model in the exchangeable ONNX format\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\n",
        "    wandb.save(\"model.onnx\")"
      ],
      "metadata": {
        "id": "OBCWuXv0nKpb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build, train and analyze the model with the pipeline\n",
        "model = model_pipeline(config)"
      ],
      "metadata": {
        "id": "gtR0exxMnN_f"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    train, test = get_data(train=True), get_data(train=False)\n",
        "    # Access batch_size using dictionary key\n",
        "    train_loader = make_loader(train, batch_size=config['batch_size'])\n",
        "    test_loader = make_loader(test, batch_size=config['batch_size'])\n",
        "\n",
        "    # Make the model\n",
        "    model = ConvNet(config['kernels'], config['classes']).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "rQtPXdHwnYDW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGbAKMEpnjyZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}