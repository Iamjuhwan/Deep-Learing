# -*- coding: utf-8 -*-
"""perceptron model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjSCcgWx3yE_5_irmIDfF2EViVRrpoZJ

# **Building a Perceptron Model from Scratch**
A perceptron is the simplest type of artificial neural network, designed for binary classification tasks
"""





"""To carry out the implementation of the model:
*   Intialize weights and bias
*   Weighted sum
*   Activation function
*   Update the weights and biases

"""

import numpy as np
import matplotlib.pyplot as plt

class perceptron:
  def __init__(self, learning_rate=0.01, epochs=100):
    '''Initialize perceptron model parameters'''
    self.learning_rate = learning_rate
    self.epochs = epochs
    self.weights = None
    self.bias = None
    self.errors = [] #Track errors

  def step_function(self,z):
    '''Step activation function'''
    return 1 if z >=0 else 0

  def fit(self,X,y):
    '''Train the perceptron on the dataset'''
    n_features = X.shape[1]
    self.weights = np.zeros(n_features)  #Intializing weights
    self.bias = 0 #initializing bias

    for epoch in range(self.epochs):
      err = 0
      for idx,x_i in enumerate(X):
        z = np.dot(x_i, self.weights) + self.bias
        y_pred = self.step_function(z)


      #Update weights and biases
      update = self.learning_rate * (y[idx]-y_pred)
      self.weights += update * x_i
      self.bias += update

      #count errors
      if update != 0:
        err += 1

      self.errors.append(err)

      #print('Epoch '+ (epoch+1) + '/' + self.epochs + ' : errors = ' + errors)
      print(f'epochs {epoch + 1}/{self.epochs} : errors = {err}' )
    print('Training Ended')

  def predict(self,X):
    '''Predict classes for input features'''
    z = np.dot(X, self.weights) + self.bias
    return np.array([self.step_function(i) for i in z])

# prompt: write a code to generate a linearly separable data set with 3 features or more, having 2 classes

import numpy as np

def generate_linearly_separable_data(num_samples, num_features, num_classes):
    """Generates a linearly separable dataset.

    Args:
        num_samples: The number of samples to generate.
        num_features: The number of features for each sample.
        num_classes: The number of classes (must be 2 for linear separability).

    Returns:
        A tuple containing:
            - X: A NumPy array of shape (num_samples, num_features) representing the features.
            - y: A NumPy array of shape (num_samples,) representing the class labels (0 or 1).
    """

    if num_classes != 2:
        raise ValueError("Number of classes must be 2 for linear separability.")

    # Generate random data points
    X = np.random.rand(num_samples, num_features)

    # Create a random hyperplane (decision boundary)
    w = np.random.rand(num_features)

    # Assign labels based on the hyperplane
    y = np.array([1 if np.dot(x, w) > 0.5 else 0 for x in X])

    return X, y

# Example usage (generating 100 samples with 3 features and 2 classes):
X, y = generate_linearly_separable_data(num_samples=100, num_features=3, num_classes=2)

# Print the first 10 samples and their labels to verify
for i in range(10):
  print(f"Sample {i+1}: Features={X[i]}, Label={y[i]}")

# Print the first 25 samples and their labels to verify
for i in range(25):
  print(f"Sample {i+1}: Features={X[i]}, Label={y[i]}")

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a linearly separable dataset
# X, y = make_classification(n_samples=100, n_features=6, n_classes=2,
#                          n_clusters_per_class=1, n_redundant=0,
#                          random_state=42)

model = perceptron(learning_rate=0.01, epochs=1000)
model.fit(X_train, y_train)

model = perceptron(learning_rate=0.01, epochs=100)
model.fit(X_train, y_train)

test_predictions = model.predict(X_test)
test_accuracy = accuracy_score(y_test, test_predictions)
print(f"Test Accuracy: {test_accuracy:.2f}")

print(classification_report(y_test, test_predictions))

sample_points = X_test[:10]
sample_labels = y_test[:10]

Predictions = model.predict(sample_points)

for i in range(10):
  print(f"Sample {i+1}: Features={sample_points[i]}, Label={sample_labels[i]}, Prediction={Predictions[i]}")

