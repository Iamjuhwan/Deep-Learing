{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBZmQOK7Atoo41Pc3CtBnM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iamjuhwan/Deep-Learing/blob/main/perceptron_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iOTQK-AbkhXp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model parameters\n",
        "def initialize_perceptron(n_features):\n",
        "    weights = np.zeros(n_features)  # Initialize weights\n",
        "    bias = 0  # Initialize bias\n",
        "    return weights, bias\n",
        ""
      ],
      "metadata": {
        "id": "oGF2cjr_k3x5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Function"
      ],
      "metadata": {
        "id": "iOqsm1Q7lBAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the step activation function\n",
        "def step_function(z):\n",
        "    '''Step activation function'''\n",
        "    return 1 if z >= 0 else 0"
      ],
      "metadata": {
        "id": "3e4JBD02k-iQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Perceptron"
      ],
      "metadata": {
        "id": "xTNdeKzVlKC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the perceptron\n",
        "def train_perceptron(X, y, learning_rate=0.01, epochs=100):\n",
        "    '''Train the perceptron on the dataset'''\n",
        "    n_features = X.shape[1]\n",
        "    weights, bias = initialize_perceptron(n_features)\n",
        "    errors = []  # Track errors for each epoch\n",
        "\n",
        "    for epoch in range(epochs): #For Every iteration\n",
        "        err = 0  # Count errors for the epoch\n",
        "        for idx, x_i in enumerate(X):\n",
        "            z = np.dot(x_i, weights) + bias\n",
        "            y_pred = step_function(z)\n",
        "\n",
        "            # Update weights and bias\n",
        "            update = learning_rate * (y[idx] - y_pred)\n",
        "            weights += update * x_i\n",
        "            bias += update\n",
        "\n",
        "            # Count errors\n",
        "            if update != 0:\n",
        "                err += 1\n",
        "\n",
        "        errors.append(err)\n",
        "        print(f'Epoch {epoch + 1}/{epochs} : errors = {err}')\n",
        "\n",
        "        # Early stopping if no errors\n",
        "        if err == 0:\n",
        "          print('Converged! Training ended early.')\n",
        "          break\n",
        "\n",
        "    print('Training Ended')\n",
        "    return weights, bias, errors"
      ],
      "metadata": {
        "id": "dmghVOXBlEbS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "dMLbS3irlZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict classes for input features\n",
        "def predict(X, weights, bias):\n",
        "    '''Predict classes for input features'''\n",
        "    z = np.dot(X, weights) + bias\n",
        "    return np.array([step_function(i) for i in z])"
      ],
      "metadata": {
        "id": "PFmyK0u7lOcW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Implementation"
      ],
      "metadata": {
        "id": "PEywW7M4liVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset (replace this with your data)\n",
        "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])  # Features\n",
        "y = np.array([1, 0, 0, 0])  # Labels\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "weights, bias, errors = train_perceptron(X, y, learning_rate, epochs)\n",
        "\n",
        "# Prediction\n",
        "predictions = predict(X, weights, bias)\n",
        "print(f\"Predictions: {predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lrRLRtElcvH",
        "outputId": "6b6bcb00-0974-4631-8842-889fdbd1adbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 : errors = 1\n",
            "Epoch 2/100 : errors = 3\n",
            "Epoch 3/100 : errors = 2\n",
            "Epoch 4/100 : errors = 2\n",
            "Epoch 5/100 : errors = 3\n",
            "Epoch 6/100 : errors = 2\n",
            "Epoch 7/100 : errors = 2\n",
            "Epoch 8/100 : errors = 0\n",
            "Converged! Training ended early.\n",
            "Training Ended\n",
            "Predictions: [1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arranging it in a class!"
      ],
      "metadata": {
        "id": "ZbH2JaQDlqIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class perceptron:\n",
        "  def __init__(self, learning_rate=0.01, epochs=100):\n",
        "    '''Initialize perceptron model parameters'''\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "    self.errors = [] #Track errors\n",
        "\n",
        "  def step_function(self,z):\n",
        "    '''Step activation function'''\n",
        "    return 1 if z >=0 else 0\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    '''Train the perceptron on the dataset'''\n",
        "    n_features = X.shape[1]\n",
        "    self.weights = np.zeros(n_features)  #Intializing weights\n",
        "    self.bias = 0 #initializing bias\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      err = 0\n",
        "      for idx,x_i in enumerate(X):\n",
        "        z = np.dot(x_i, self.weights) + self.bias\n",
        "        y_pred = self.step_function(z)\n",
        "\n",
        "\n",
        "        #Update weights and biases\n",
        "        update = self.learning_rate * (y[idx]-y_pred)\n",
        "        self.weights += update * x_i\n",
        "        self.bias += update\n",
        "\n",
        "        #count errors\n",
        "        if update != 0:\n",
        "          err += 1\n",
        "\n",
        "      self.errors.append(err)\n",
        "\n",
        "      print(f'epochs {epoch + 1}/{self.epochs} : errors = {err}' )\n",
        "\n",
        "      # Early stopping if no errors\n",
        "      if err == 0:\n",
        "          print('Converged! Training ended early.')\n",
        "          break\n",
        "    print('Training Ended')\n",
        "\n",
        "  def predict(self,X):\n",
        "    '''Predict classes for input features'''\n",
        "    z = np.dot(X, self.weights) + self.bias\n",
        "    return np.array([self.step_function(i) for i in z])\n"
      ],
      "metadata": {
        "id": "-BeVXpnfll9C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the class"
      ],
      "metadata": {
        "id": "8HeJsHjElw_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a code to generate a linearly separable data set with 3 features or more, having 2 classes\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def generate_linearly_separable_data(num_samples, num_features, num_classes):\n",
        "    if num_classes != 2:\n",
        "        raise ValueError(\"Number of classes must be 2 for linear separability.\")\n",
        "\n",
        "    # Generate random data points\n",
        "    X = np.random.rand(num_samples, num_features)\n",
        "\n",
        "    # Create a random hyperplane (decision boundary)\n",
        "    w = np.random.rand(num_features)\n",
        "\n",
        "    # Assign labels based on the hyperplane\n",
        "    y = np.array([1 if np.dot(x, w) > 0.5 else 0 for x in X])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Example usage (generating 100 samples with 3 features and 2 classes):\n",
        "X, y = generate_linearly_separable_data(num_samples=100, num_features=3, num_classes=2)\n",
        "\n",
        "# Print the first 10 samples and their labels to verify\n",
        "for i in range(10):\n",
        "  print(f\"Sample {i+1}: Features={X[i]}, Label={y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeyS3eSUluOa",
        "outputId": "885a0530-213a-4db2-e08b-fa1fa3e4ef71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: Features=[0.74698561 0.85709267 0.17789888], Label=1\n",
            "Sample 2: Features=[0.43986982 0.74833612 0.97140321], Label=1\n",
            "Sample 3: Features=[0.21876682 0.37714947 0.84789098], Label=1\n",
            "Sample 4: Features=[0.75910223 0.80127251 0.44589018], Label=1\n",
            "Sample 5: Features=[0.44242179 0.22093144 0.65912623], Label=1\n",
            "Sample 6: Features=[0.27613048 0.70604422 0.69586943], Label=1\n",
            "Sample 7: Features=[0.80979171 0.34717556 0.38698119], Label=1\n",
            "Sample 8: Features=[0.29454181 0.6560294  0.43942049], Label=1\n",
            "Sample 9: Features=[0.33791913 0.77735768 0.64803608], Label=1\n",
            "Sample 10: Features=[0.38395588 0.96178596 0.27356566], Label=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FWTChHqMlzFs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = perceptron(learning_rate=0.001, epochs=100)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5SfmLfUl2e_",
        "outputId": "ba91773c-27d6-472f-d336-fd0057837882"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs 1/100 : errors = 26\n",
            "epochs 2/100 : errors = 14\n",
            "epochs 3/100 : errors = 9\n",
            "epochs 4/100 : errors = 14\n",
            "epochs 5/100 : errors = 5\n",
            "epochs 6/100 : errors = 0\n",
            "Converged! Training ended early.\n",
            "Training Ended\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)"
      ],
      "metadata": {
        "id": "4k_78txol4tu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4GT3eBsl8PW",
        "outputId": "e08e9ab3-0ff6-41c0-e94e-e7ab1cc0dbbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2B08CN9l-FK",
        "outputId": "4101b61a-d360-43ce-b6cb-69db7a359c75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92         6\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.93      0.96      0.94        20\n",
            "weighted avg       0.96      0.95      0.95        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on sample points from test set\n",
        "sample_points = X_test[:50]\n",
        "predictions = model.predict(sample_points)\n",
        "\n",
        "print(\"\\nSample Predictions from Test Set:\")\n",
        "print(\"--------------------------------\")\n",
        "for i, (point, pred, actual) in enumerate(zip(sample_points, predictions, y_test[:50])):\n",
        "    print(f\"Point {i+1}: {point} -> Predicted: {pred}, Actual: {actual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXmMcD13mARk",
        "outputId": "5d66687f-cb26-441c-b6fb-cfcae40872ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions from Test Set:\n",
            "--------------------------------\n",
            "Point 1: [0.04580942 0.35897919 0.79331304] -> Predicted: 1, Actual: 1\n",
            "Point 2: [0.16862532 0.05438765 0.83824711] -> Predicted: 1, Actual: 1\n",
            "Point 3: [0.01563737 0.59178978 0.35691909] -> Predicted: 0, Actual: 0\n",
            "Point 4: [0.0387781  0.548138   0.61599532] -> Predicted: 1, Actual: 1\n",
            "Point 5: [0.67918305 0.0578973  0.27920612] -> Predicted: 0, Actual: 0\n",
            "Point 6: [0.5988575  0.89742586 0.34004658] -> Predicted: 1, Actual: 1\n",
            "Point 7: [0.6004812  0.26815252 0.82744411] -> Predicted: 1, Actual: 1\n",
            "Point 8: [0.17367256 0.07621013 0.56540669] -> Predicted: 0, Actual: 0\n",
            "Point 9: [0.94401564 0.48396159 0.41752243] -> Predicted: 1, Actual: 1\n",
            "Point 10: [0.74698561 0.85709267 0.17789888] -> Predicted: 1, Actual: 1\n",
            "Point 11: [0.79236256 0.81887259 0.8534306 ] -> Predicted: 1, Actual: 1\n",
            "Point 12: [0.03675086 0.99974109 0.78842842] -> Predicted: 1, Actual: 1\n",
            "Point 13: [0.025187   0.64355428 0.4925189 ] -> Predicted: 0, Actual: 1\n",
            "Point 14: [0.22154653 0.85322819 0.98322098] -> Predicted: 1, Actual: 1\n",
            "Point 15: [0.37981054 0.11157914 0.4423749 ] -> Predicted: 0, Actual: 0\n",
            "Point 16: [0.44242179 0.22093144 0.65912623] -> Predicted: 1, Actual: 1\n",
            "Point 17: [0.7236983  0.43907677 0.2096533 ] -> Predicted: 0, Actual: 0\n",
            "Point 18: [0.56995248 0.4466261  0.47118981] -> Predicted: 1, Actual: 1\n",
            "Point 19: [0.51306201 0.7405765  0.7288354 ] -> Predicted: 1, Actual: 1\n",
            "Point 20: [0.29081029 0.09171825 0.55776641] -> Predicted: 0, Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a linearly separable dataset\n",
        "X, y = make_classification(n_samples=100, n_features=6, n_classes=2,\n",
        "                         n_clusters_per_class=1, n_redundant=0,\n",
        "                         random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
      ],
      "metadata": {
        "id": "6Xh9EBqAmEV1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = perceptron(learning_rate=0.001, epochs=100)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLGhbgQLmHoq",
        "outputId": "dfef2cbb-7ac2-491b-b187-c786780daebf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs 1/100 : errors = 9\n",
            "epochs 2/100 : errors = 5\n",
            "epochs 3/100 : errors = 1\n",
            "epochs 4/100 : errors = 1\n",
            "epochs 5/100 : errors = 0\n",
            "Converged! Training ended early.\n",
            "Training Ended\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHwhQzGqmJ19",
        "outputId": "fa091401-991e-428c-ff6a-e6e42ca88b81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM6k15JomN9f",
        "outputId": "0b75f3e7-22b8-41d9-b5b2-ac5e5c2653bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction on sample point from test data\n",
        "sample_points = X_test[:50]\n",
        "\n",
        "predictions = model.predict(sample_points)\n",
        "\n",
        "print(\"\\nSample Predictions from Test Set:\")\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "for i, (point, pred, actual) in enumerate(zip(sample_points, predictions, y_test[:50])):\n",
        "    print(f\"Point {i+1}: {point} -> Predicted: {pred}, Actual: {actual}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C_5013vmRIs",
        "outputId": "7c9e3be0-dd71-471d-c366-29ae612a8ad5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions from Test Set:\n",
            "--------------------------------\n",
            "Point 1: [-0.02090159 -0.59157139  0.11732738 -0.76408578  1.29021194  1.2776649 ] -> Predicted: 0, Actual: 0\n",
            "Point 2: [-0.71530371  0.21645859  0.67959775 -0.36699364  1.88782031 -0.73036663] -> Predicted: 0, Actual: 0\n",
            "Point 3: [ 0.2597225  -1.66152006 -0.90431663  1.11434941  1.04031359  0.63859246] -> Predicted: 1, Actual: 1\n",
            "Point 4: [ 0.50091719  0.75138712 -0.97755524  2.50225822  2.54881729  0.09933231] -> Predicted: 1, Actual: 1\n",
            "Point 5: [ 1.16316375  0.46210347  0.01023306 -0.33281274  1.83708868 -0.98150865] -> Predicted: 0, Actual: 0\n",
            "Point 6: [ 0.75698862  1.35563786 -0.92216532  0.19690952  0.09145925  0.86960592] -> Predicted: 1, Actual: 1\n",
            "Point 7: [-0.47103831 -1.40746377  0.23204994 -1.28981425  0.51142713 -1.44808434] -> Predicted: 0, Actual: 0\n",
            "Point 8: [-1.3044695  -0.93987979  0.66967255  0.82180719  0.73902766  0.36659825] -> Predicted: 1, Actual: 1\n",
            "Point 9: [ 0.85765962 -1.00252936 -0.15993853 -2.2632312  -0.40020814 -0.01901621] -> Predicted: 0, Actual: 0\n",
            "Point 10: [-0.86041337 -0.57689187 -0.38455554  2.90114736  3.07752729  1.00629281] -> Predicted: 1, Actual: 1\n",
            "Point 11: [-1.66940528  0.57059867  0.54336019  0.74491926  0.80375081 -0.66262376] -> Predicted: 1, Actual: 1\n",
            "Point 12: [ 0.38406545 -0.08912004 -0.03269475  2.25911758  2.33026777 -2.0674421 ] -> Predicted: 1, Actual: 1\n",
            "Point 13: [-0.58936476 -0.6929096   0.8496021  -1.38029525  0.69840909  0.35701549] -> Predicted: 0, Actual: 0\n",
            "Point 14: [ 1.62861555 -0.0555477  -1.38010146  0.12054434  0.01258051 -1.70338244] -> Predicted: 1, Actual: 1\n",
            "Point 15: [-0.44004449 -1.43586215  0.13074058 -0.70808284  1.43117438  1.44127329] -> Predicted: 0, Actual: 0\n",
            "Point 16: [-0.23894805  0.75539123 -0.90756366  0.65689322  0.59137345 -0.57677133] -> Predicted: 1, Actual: 1\n",
            "Point 17: [ 0.28977486 -0.32602353  2.0754008   2.83324852  3.08402116  0.8711247 ] -> Predicted: 1, Actual: 1\n",
            "Point 18: [ 1.76545424  0.91786195  0.40498171 -0.57301231  1.61550606 -1.26088395] -> Predicted: 0, Actual: 0\n",
            "Point 19: [ 0.82541635  0.02100384  0.81350964 -0.85545993  1.03307436  1.30547881] -> Predicted: 0, Actual: 0\n",
            "Point 20: [ 0.87232064 -0.80829829  0.18334201 -0.73168763  1.2349949   2.18980293] -> Predicted: 0, Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qRk_JB6amy4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}